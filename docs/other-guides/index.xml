<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubeflow – Further Setup and Troubleshooting</title>
    <link>http://osmatrix.github.io/docs/other-guides/</link>
    <description>Recent content in Further Setup and Troubleshooting on Kubeflow</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	  <atom:link href="http://osmatrix.github.io/docs/other-guides/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Virtual Developer Environments</title>
      <link>http://osmatrix.github.io/docs/other-guides/virtual-dev/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/virtual-dev/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>Docs: Configuring Kubeflow with kfctl and kustomize</title>
      <link>http://osmatrix.github.io/docs/other-guides/kustomize/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/kustomize/</guid>
      <description>
        
        
        &lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Kfctl is the Kubeflow command-line interface (CLI) that you can use to
install and configure Kubeflow.&lt;/p&gt;
&lt;p&gt;Kubeflow makes use of &lt;a href=&#34;https://kustomize.io/&#34;&gt;kustomize&lt;/a&gt; to help customize YAML
configurations. With kustomize, you can traverse a Kubernetes manifest to add, 
remove, or update configuration options without forking the manifest. A 
&lt;em&gt;manifest&lt;/em&gt; is a YAML file containing a description of the applications that you 
want to include in your Kubeflow deployment.&lt;/p&gt;
&lt;h2 id=&#34;overview-of-kfctl-and-kustomize&#34;&gt;Overview of kfctl and kustomize&lt;/h2&gt;
&lt;p&gt;This section describes how kfctl works with kustomize to set up your 
Kubeflow deployment.&lt;/p&gt;
&lt;h3 id=&#34;the-kubeflow-deployment-process&#34;&gt;The Kubeflow deployment process&lt;/h3&gt;
&lt;p&gt;Kfctl is the Kubeflow CLI that you can use to set up a Kubernetes cluster with 
Kubeflow installed, or to deploy Kubeflow to an existing Kubernetes cluster. 
See the &lt;a href=&#34;http://osmatrix.github.io/docs/started/getting-started/&#34;&gt;Kubeflow getting-started guide&lt;/a&gt; for
installation instructions based on your deployment scenario.&lt;/p&gt;
&lt;p&gt;The kfctl deployment process includes the following commands:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kfctl build&lt;/code&gt; - (Optional) Creates configuration files defining the various
resources in your deployment but does not deploy Kubeflow.
You only need to run &lt;code&gt;kfctl build&lt;/code&gt; if you want
to edit the resources before running &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfctl apply&lt;/code&gt; - Creates or updates the resources.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kfctl delete&lt;/code&gt; - Deletes the resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;specifying-a-configuration-file-when-initializing-your-deployment&#34;&gt;Specifying a configuration file when initializing your deployment&lt;/h3&gt;
&lt;p&gt;When you install Kubeflow, the deployment process uses one of a few possible
YAML configuration files to bootstrap the configuration. You can see all the
&lt;a href=&#34;https://github.com/kubeflow/manifests/tree/master/kfdef&#34;&gt;configuration files on 
GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As an example, this guide uses the 
&lt;a href=&#34;https://github.com/kubeflow/manifests/blob/master/kfdef/kfctl_k8s_istio.yaml&#34;&gt;kfctl_k8s_istio.yaml&lt;/a&gt;
configuration. For more details about this configuration, see the
&lt;a href=&#34;http://osmatrix.github.io/docs/started/k8s/kfctl-k8s-istio/&#34;&gt;kfctl_k8s_istio deployment guide&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Typically, you specify the configuration file with a &lt;code&gt;-f &amp;lt;config-file&amp;gt;&lt;/code&gt; 
parameter when you run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;. The following example
uses &lt;code&gt;kfctl build&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set KF_NAME to the name of your Kubeflow deployment. You also use this&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# value as directory name when creating your configuration directory.&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For example, your deployment name can be &amp;#39;my-kubeflow&amp;#39; or &amp;#39;kf-test&amp;#39;.&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;your choice of name &lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;for&lt;/span&gt; the Kubeflow deployment&amp;gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set the path to the base directory where you want to store one or more&lt;/span&gt; 
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Kubeflow deployments. For example, /opt/.&lt;/span&gt;
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Then set the Kubeflow application directory for this deployment.&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;path to a base directory&amp;gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;BASE_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;/&lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_NAME&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Set the URI of the configuration file to use when deploying Kubeflow.&lt;/span&gt; 
&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# For example:&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;CONFIG_URI&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;https://raw.githubusercontent.com/kubeflow/manifests/v1.0-branch/kfdef/kfctl_k8s_istio.v1.0.0.yaml&amp;#34;&lt;/span&gt;

&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# Create your Kubeflow configurations:&lt;/span&gt;
mkdir -p &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color:#204a87&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;KF_DIR&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
kfctl build -V -f &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;CONFIG_URI&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Kfctl has now built the configuration files in your Kubeflow application
directory (see &lt;a href=&#34;#kubeflow-directory&#34;&gt;below&lt;/a&gt;) but has not yet deployed Kubeflow.
To complete the deployment, run &lt;code&gt;kfctl apply&lt;/code&gt;. See the next section on 
&lt;a href=&#34;#apply-config&#34;&gt;applying the configuration&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h3 id=&#34;applying-the-configuration-to-your-kubeflow-cluster&#34;&gt;Applying the configuration to your Kubeflow cluster&lt;/h3&gt;
&lt;p&gt;When you first run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;, kfctl creates
a local version of the YAML configuration file,
which you can further customize if necessary.&lt;/p&gt;
&lt;p&gt;Follow these steps to apply the configurations to your Kubeflow cluster:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set an environment variable pointing to your local configuration file.
For example, this guide uses the &lt;code&gt;kfctl_k8s_istio.v1.0.0.yaml&lt;/code&gt; 
configuration. If you chose a different configuration in the previous step, 
you must change the file name to reflect your configuration:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;export CONFIG_FILE=${KF_DIR}/kfctl_k8s_istio.v1.0.0.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;ol&gt;
&lt;li&gt;Apply the configurations:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;kfctl apply -V -f ${CONFIG_FILE}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h3 id=&#34;your-kubeflow-directory-layout&#34;&gt;Your Kubeflow directory layout&lt;/h3&gt;
&lt;p&gt;Your Kubeflow application directory is the directory where you choose to store 
your Kubeflow configurations during deployment. This guide refers to the
directory as &lt;code&gt;${KF_DIR}&lt;/code&gt;. The directory contains the  following files and 
directories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;${CONFIG_FILE}&lt;/strong&gt; is a YAML file that stores your primary Kubeflow 
configuration in the form of a &lt;code&gt;KfDef&lt;/code&gt; Kubernetes object.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This file is a &lt;strong&gt;copy&lt;/strong&gt; of the &lt;a href=&#34;https://github.com/kubeflow/manifests/tree/master/kfdef&#34;&gt;GitHub-based configuration YAML 
file&lt;/a&gt; that
you used when deploying Kubeflow.&lt;/li&gt;
&lt;li&gt;When you first run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;, kfctl creates
a local version of the configuration file at &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;,
which you can further customize if necessary.&lt;/li&gt;
&lt;li&gt;The YAML defines each Kubeflow application as a kustomize package.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;platform-name&amp;gt;_config&lt;/strong&gt; is a directory that contains 
configurations specific to your chosen platform or cloud provider. 
For example, &lt;code&gt;gcp_config&lt;/code&gt; or &lt;code&gt;aws_config&lt;/code&gt;. This 
directory may or may not be present, depending on your setup.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The directory is created when you run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;To customize these configurations, you can modify parameters
in your &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;, and then run &lt;code&gt;kfctl apply&lt;/code&gt; to apply
the configuration to your Kubeflow cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;kustomize&lt;/strong&gt; is a directory that contains Kubeflow application manifests.
That is, the directory contains the kustomize packages for the Kubeflow 
applications that are included in your deployment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The directory is created when you run &lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;To customize these configurations, you can modify parameters
in your &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;, and then run &lt;code&gt;kfctl apply&lt;/code&gt; to apply
the configuration to your Kubeflow cluster.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;how-your-configuration-is-generated&#34;&gt;How your configuration is generated&lt;/h3&gt;
&lt;p&gt;The content of your &lt;code&gt;${CONFIG_FILE}&lt;/code&gt; is the result of running kustomize 
on the base and overlay &lt;code&gt;kustomization.yaml&lt;/code&gt; files in the 
&lt;a href=&#34;https://github.com/kubeflow/manifests/tree/master/kfdef&#34;&gt;Kubeflow manifests&lt;/a&gt;. 
The overlays reflect the configuration file that you specify when running 
&lt;code&gt;kfctl build&lt;/code&gt; or &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Below are some examples of configuration files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/manifests/blob/master/kfdef/kfctl_k8s_istio.yaml&#34;&gt;kfctl_k8s_istio.yaml&lt;/a&gt; 
to install Kubeflow on an existing Kubernetes cluster.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/manifests/blob/master/kfdef/kfctl_istio_dex.yaml&#34;&gt;kfctl_istio_dex.yaml&lt;/a&gt;
to install Kubeflow on an existing Kubernetes cluster with Dex and Istio for
authentication.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/manifests/blob/master/kfdef/kfctl_gcp_iap.yaml&#34;&gt;kfctl_gcp_iap.yaml&lt;/a&gt;
to create a Google Kubernetes Engine (GKE) cluster with Kubeflow using
Cloud Identity-Aware Proxy (Cloud IAP) for access control.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The kustomize package manager in kfctl uses the information in your
&lt;code&gt;${CONFIG_FILE}&lt;/code&gt; to traverse the directories under the 
&lt;a href=&#34;https://github.com/kubeflow/manifests&#34;&gt;Kubeflow manifests&lt;/a&gt; and to 
create kustomize build targets based on the manifests.&lt;/p&gt;
&lt;h2 id=&#34;installing-kustomize&#34;&gt;Installing kustomize&lt;/h2&gt;
&lt;p&gt;Make sure that you have the minimum required version of kustomize:
&lt;!-- raw HTML omitted --&gt;2.0.3&lt;!-- raw HTML omitted --&gt; or later.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Follow the &lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/INSTALL.md&#34;&gt;kustomize installation
guide&lt;/a&gt;,
choosing the relevant options for your operating system. For example, if
you&amp;rsquo;re on Linux:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Set some variables for the operating system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export opsys=linux
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the kustomize binary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s https://api.github.com/repos/kubernetes-sigs/kustomize/releases |\
grep browser_download |\
grep download/kustomize |\
grep -m 1 $opsys |\
cut -d &#39;&amp;quot;&#39; -f 4 |\
xargs curl -O -L
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Move the binary:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mkdir -p ${HOME}/bin
mv kustomize_*_${opsys}_amd64 ${HOME}/bin/kustomize
chmod u+x ${HOME}/bin/kustomize
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Include the &lt;code&gt;kustomize&lt;/code&gt; command in your path:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export PATH=$PATH:${HOME}/bin/kustomize
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;modifying-configuration-before-deployment&#34;&gt;Modifying configuration before deployment&lt;/h2&gt;
&lt;p&gt;Kustomize lets you customize raw, template-free YAML files for multiple
purposes, leaving the original YAML untouched and usable as is.&lt;/p&gt;
&lt;p&gt;You can use the following command to build and apply kustomize directories:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kustomize build &amp;lt;kustomization_directory&amp;gt; | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;a href=&#34;https://github.com/kubeflow/manifests&#34;&gt;Kubeflow manifests repo&lt;/a&gt; contains
kustomize build targets, each with a &lt;code&gt;base&lt;/code&gt; directory. You can use kustomize to
generate YAML output and pass it to kfctl. You can also make
changes to the kustomize targets in the manifests repo as needed.&lt;/p&gt;
&lt;h2 id=&#34;modifying-the-configuration-of-an-existing-deployment&#34;&gt;Modifying the configuration of an existing deployment&lt;/h2&gt;
&lt;p&gt;To customize the Kubeflow resources running within the cluster, you can modify
parameters in your &lt;code&gt;${CONFIG_FILE}&lt;/code&gt; file. Then re-run &lt;code&gt;kfctl apply&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, to modify settings for the Spartakus usage reporting tool within 
your Kubeflow deployment:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Edit the configuration file at &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find and replace the parameter values for &lt;code&gt;spartakus&lt;/code&gt; to suit your
requirements:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; - kustomizeConfig:
     parameters:
     - initRequired: true
         name: usageId
         value: &amp;lt;randomly-generated-id&amp;gt;
     - initRequired: true
         name: reportUsage
         value: &amp;quot;true&amp;quot;
     repoRef:
         name: manifests
         path: common/spartakus
     name: spartakus
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regenerate and deploy your Kubeflow resources:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd ${KF_DIR}
kfctl apply -V -f ${CONFIG_FILE}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;more-examples&#34;&gt;More examples&lt;/h3&gt;
&lt;p&gt;For examples of customizing your deployment, see the guide to &lt;a href=&#34;http://osmatrix.github.io/docs/gke/customizing-gke/&#34;&gt;customizing 
Kubeflow on GKE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For information about how Kubeflow uses Spartakus, see the guide to
&lt;a href=&#34;http://osmatrix.github.io/docs/other-guides/usage-reporting/&#34;&gt;usage reporting&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;more-about-kustomize&#34;&gt;More about kustomize&lt;/h2&gt;
&lt;p&gt;Below are some useful kustomize terms, from the 
&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/blob/master/docs/glossary.md&#34;&gt;kustomize glossary&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;base:&lt;/strong&gt; A combination of a kustomization and resource(s). Bases can be
referred to by other kustomizations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;kustomization:&lt;/strong&gt; Refers to a &lt;code&gt;kustomization.yaml&lt;/code&gt; file, or more generally to
a directory containing the &lt;code&gt;kustomization.yaml&lt;/code&gt; file and all the relative file 
paths that the YAML file references.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;overlay:&lt;/strong&gt; A combination of a kustomization that refers to a base, and a
patch. An overlay may have multiple bases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;patch:&lt;/strong&gt; General instructions to modify a resource.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;resource:&lt;/strong&gt; Any valid YAML file that defines an object with a kind and a
metadata/name field.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;target:&lt;/strong&gt; The argument to &lt;code&gt;kustomize build&lt;/code&gt;. For example, 
&lt;code&gt;kustomize build $TARGET&lt;/code&gt;. A target must be a path or a URL to a 
kustomization. A target can be a base or an overlay.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;variant:&lt;/strong&gt; The outcome of applying an overlay to a base.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read more about kustomize in the
&lt;a href=&#34;https://github.com/kubernetes-sigs/kustomize/tree/master/docs&#34;&gt;kustomize documentation&lt;/a&gt;.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Kubeflow On-prem in a Multi-node Kubernetes Cluster</title>
      <link>http://osmatrix.github.io/docs/other-guides/kubeflow-on-multinode-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/kubeflow-on-multinode-cluster/</guid>
      <description>
        
        
        &lt;p&gt;This guide describes how to set up Kubeflow on premises (on-prem) in a multi-node cluster using &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34;&gt;dynamic volume provisioning&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;vanilla-on-prem-kubeflow-installation&#34;&gt;Vanilla on-prem Kubeflow installation&lt;/h2&gt;
&lt;p&gt;In order to install Kubeflow in an on-prem Kubernetes cluster, follow the guide
to &lt;a href=&#34;http://osmatrix.github.io/docs/started/k8s&#34;&gt;installing Kubeflow on existing clusters&lt;/a&gt;, which works 
for single node and multi-node clusters.&lt;/p&gt;
&lt;p&gt;At the end of the installation, some Persistent Volume Claims (PVCs) might be unbound. To fix this issue, see the troubleshooting section &lt;a href=&#34;http://osmatrix.github.io/docs/other-guides/troubleshooting/#pods-stuck-in-pending-state&#34;&gt;Pods stuck in Pending state&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, when you set up Kubeflow in a multi-node cluster you might run into an additional issue: you can&amp;rsquo;t create a &lt;em&gt;HostPath&lt;/em&gt; PersistentVolume (which exposes a filesystem directory to a Pod), because this type of PersistentVolume only works on a single node cluster.&lt;/p&gt;
&lt;h2 id=&#34;background-on-kubernetes-storage&#34;&gt;Background on Kubernetes storage&lt;/h2&gt;
&lt;p&gt;Kubernetes defines several ways to attach Volumes to Pods.&lt;/p&gt;
&lt;p&gt;The best practice is to decouple storage needs (&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims&#34;&gt;Persistent Volume Claims&lt;/a&gt; or PVCs) from actual storage (&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;Persistent Volumes&lt;/a&gt; or PVs). Kubernetes provisions PVs based on available resources. There are &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes&#34;&gt;several types&lt;/a&gt; of PV.&lt;/p&gt;
&lt;p&gt;Cloud providers define mechanisms to allocate PVs based on existing PVCs using their storage infrastructure; on-prem clusters must provision their PVs according the existing capability of the system.&lt;/p&gt;
&lt;p&gt;In development clusters or single node clusters, you can bind PVCs to HostPath PVs, which are a particular kind of volumes that maps the Pod&amp;rsquo;s Volume to a directory of the filesystem.&lt;/p&gt;
&lt;p&gt;This approach, however, is not a feasible solution in multi-node clusters. A Pod can be on different nodes during its lifecycle: Kubernetes can kill and restart it on another node at any time based on the resources available in the cluster. In this scenario, the migrated Pod will not find its old data after restarting on a new node.&lt;/p&gt;
&lt;p&gt;A common solution is to mount a remote volume in the Pods so that any node in the cluster can reach it.&lt;/p&gt;
&lt;p&gt;The rest of this document describes the following tasks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how to associate a remote NFS volume to Kubeflow Pods so you don&amp;rsquo;t have any problems when the Pod is scheduled on different cluster nodes during its lifecycle.&lt;/li&gt;
&lt;li&gt;how to simplify cluster administration by using &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34;&gt;dynamic provisioning&lt;/a&gt;, which lets Kubernetes create a different PV for each PVC without manual intervention.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The best way to avoid PVC problems is to complete both of these steps before you install Kubeflow on your Kubernetes cluster. However, if you have already installed Kubeflow on your cluster and want to resolve PVC problems, complete the steps and then read the &lt;a href=&#34;#in-case-of-existing-kubeflow-installation&#34;&gt;In case of existing Kubeflow installation&lt;/a&gt; section at the end of this document.&lt;/p&gt;
&lt;h2 id=&#34;nfs-persistent-volumes&#34;&gt;NFS Persistent Volumes&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_File_System&#34;&gt;NFS&lt;/a&gt; is a popular distributed filesystem commonly used in Unix operating systems.&lt;/p&gt;
&lt;p&gt;You can use an NFS server to create PVs where Pods can write their data.&lt;/p&gt;
&lt;p&gt;In order to do this you must provide an NFS server with an IP reachable from inside the Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;If an NFS volume is not available to your cluster, you can transform one of the cluster&amp;rsquo;s nodes into an NFS server with the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;sudo apt install nfs-common
sudo apt install nfs-kernel-server
sudo mkdir /nfsroot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Than you need to configure &lt;code&gt;/etc/exports&lt;/code&gt; to share that directory:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;/nfsroot 192.168.0.0/16&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;rw,no_root_squash,no_subtree_check&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Notice that 192.168.0.0 is the nodes&amp;rsquo; Classless Inter-Domain Routing (CIDR), not the Kubernetes CIDR.&lt;/p&gt;
&lt;h3 id=&#34;nfs-client&#34;&gt;NFS Client&lt;/h3&gt;
&lt;p&gt;Each node of the cluster must be able to establish a connection to the NFS server.
To enable this, install the following NFS client library on each node:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;sudo apt install nfs-common
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;install-dynamic-provisioner&#34;&gt;Install Dynamic Provisioner&lt;/h2&gt;
&lt;p&gt;Now you can create NFS PVs to enable each Pod to write its own data 
in a common place from any node.&lt;/p&gt;
&lt;p&gt;In order to successfully complete the Kubeflow installation, your cluster must have an NFS PV for each PVC to bind to.&lt;/p&gt;
&lt;p&gt;Since creating NFS PVs can be tedious, you can set up &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34;&gt;Dynamic provisioning&lt;/a&gt; to automatically create PVs based on existing PVCs.&lt;/p&gt;
&lt;p&gt;Follow the instructions in this section to install a Dynamic Provisioner for NFS volumes in your cluster.&lt;/p&gt;
&lt;h3 id=&#34;install-helm&#34;&gt;Install Helm&lt;/h3&gt;
&lt;p&gt;To install a Dynamic Provisioner, you must first install Helm, the Kubernetes package manager.
You can follow &lt;a href=&#34;https://helm.sh/docs/using_helm/#install-helm&#34;&gt;this guide&lt;/a&gt; to install it in a couple of steps.&lt;/p&gt;
&lt;h3 id=&#34;install-nfs-provisioner&#34;&gt;Install NFS Provisioner&lt;/h3&gt;
&lt;p&gt;Next, install &lt;a href=&#34;https://github.com/helm/charts/tree/master/stable/nfs-client-provisioner&#34;&gt;NFS client provisioner&lt;/a&gt;, which is a Dynamic Provisioner that can create PVs for any PVC for a given &lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes/&#34;&gt;storage class&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A storage class is a label associated to volumes to specify a class of storage: 
storage class definitions make it possible to query and provision volumes with different performances or capabilities
(For example, SSD or slower disks).&lt;/p&gt;
&lt;p&gt;A special storage class is &lt;em&gt;default&lt;/em&gt;: any PV or PVC that doesn&amp;rsquo;t
specify one is associated to it.&lt;/p&gt;
&lt;p&gt;You can install NFS Client Provisioner with Helm:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;helm install &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  --name nfs-client-provisioner &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  --set nfs.server&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&amp;lt;NFS Server IP&amp;gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  --set nfs.path&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;/exported/path &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  --set storageClass.name&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;nfs &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  --set storageClass.defaultClass&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#204a87&#34;&gt;true&lt;/span&gt; &lt;span style=&#34;color:#4e9a06&#34;&gt;\&lt;/span&gt;
  stable/nfs-client-provisioner
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The component in the system will add an &lt;em&gt;nfs&lt;/em&gt; Storage Class that you can see with the following command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get storageclass -n kubeflow

NAME                   PROVISIONER                            AGE
nfs &lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;(&lt;/span&gt;default&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;)&lt;/span&gt;          cluster.local/nfs-client-provisioner   6h13m
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Notice that the installation command set the &lt;code&gt;storageClass.defaultClass&lt;/code&gt; parameter to &lt;code&gt;true&lt;/code&gt;. 
This sets the &lt;em&gt;nfs&lt;/em&gt; as the default storage class. 
Therefore when you install Kubeflow, all PVCs will be labelled with the &lt;em&gt;nfs&lt;/em&gt; storage class.&lt;/p&gt;
&lt;h2 id=&#34;finally-install-kubeflow&#34;&gt;Finally: install Kubeflow&lt;/h2&gt;
&lt;p&gt;Now that you have prepared your on-prem, multi-node Kubernetes cluster to manage 
volumes using an NFS server, you can install Kubeflow by following the guide to 
&lt;a href=&#34;http://osmatrix.github.io/docs/started/k8s&#34;&gt;installing Kubeflow on existing clusters&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;After installing Kubeflow, notice that that Kubernetes binds each PVC created by Kubeflow to an automatically created PV with the &lt;em&gt;nfs&lt;/em&gt; storage class. Notice also that the provisioner has created a directory for each PVC inside the root NFS directory.&lt;/p&gt;
&lt;h2 id=&#34;in-case-of-existing-kubeflow-installation&#34;&gt;In case of existing Kubeflow installation&lt;/h2&gt;
&lt;p&gt;If you set up Dynamic Provisioning &lt;em&gt;after&lt;/em&gt; installing Kubeflow, you must change the storage class on your existing unbound PVCs.&lt;/p&gt;
&lt;p&gt;To perform this task you need to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Download existing PVCs.&lt;/li&gt;
&lt;li&gt;Change their storage class.&lt;/li&gt;
&lt;li&gt;Delete and recreate them in the cluster.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For downloading the existing PVCs, first get list of all PVCs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pvc --all-namespaces
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This will show the list of PVCs with details including &lt;code&gt;NAMESPACE&lt;/code&gt;, &lt;code&gt;STATUS&lt;/code&gt;, &lt;code&gt;STORAGECLASS&lt;/code&gt;.
(For example, &lt;code&gt;mysql-pv-claim&lt;/code&gt; in &lt;code&gt;kubeflow&lt;/code&gt; namespace and &lt;code&gt;authservice-pvc&lt;/code&gt; in &lt;code&gt;istio-systems&lt;/code&gt; namespace).&lt;/p&gt;
&lt;p&gt;Download the PVCs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl get pvc/&amp;lt;PVC-NAME&amp;gt; -n &amp;lt;NAMESPACE&amp;gt; -o yaml &amp;gt; &amp;lt;PVC-NAME&amp;gt;.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And then modify the YAML files to add the right &lt;code&gt;storageClassName&lt;/code&gt; under the &lt;code&gt;spec&lt;/code&gt; section. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#8f5902;font-style:italic&#34;&gt;# mysql-pv-claim.yaml&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;v1&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;PersistentVolumeClaim&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;metadata&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;mysql-pv-claim&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;namespace&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;kubeflow&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;...&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;spec&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;storageClassName&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;nfs&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;...&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;After modifying all downloaded PVCs, remove the old PVCs. Note that the field &lt;code&gt;&amp;lt;PVC-NAME&amp;gt;&lt;/code&gt; below stands for the downloaded YAML file name.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl delete -f &amp;lt;PVC-NAME&amp;gt;.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Finally, add the modified PVCs:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;kubectl apply -f &amp;lt;PVC-NAME&amp;gt;.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The PVCs are now bound to your NFS storage.&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;NFS is a remote filesystem that is high performant in reading but slower in writing.
If you have to write a huge amount of data in your workflow, NFS might not be the right choice.&lt;/p&gt;
&lt;p&gt;Ensure that you are using version 4 of NFS (instead of version 3): NFS 3 can have some problems like 
partial writing of documents and it does not support authentication.&lt;/p&gt;
&lt;p&gt;In this document you used one of the nodes as an NFS server. This is not a good idea for a production
environment because you will have a single point of failure in your cluster.&lt;/p&gt;
&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;
&lt;p&gt;This short guide is not intended to be complete. 
For more information about the following Kubernetes resources, please refer to the official documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims&#34;&gt;Persistent Volume Claims&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;Persistent Volume&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/storage-classes/&#34;&gt;Storage Class&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes&#34;&gt;Storage Types Supported by Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34;&gt;Dynamic Provisioning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Usage Reporting</title>
      <link>http://osmatrix.github.io/docs/other-guides/usage-reporting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/usage-reporting/</guid>
      <description>
        
        
        &lt;p&gt;When enabled, Kubeflow will report &lt;strong&gt;anonymous&lt;/strong&gt; usage data using 
&lt;a href=&#34;https://github.com/kubernetes-incubator/spartakus&#34;&gt;Spartakus&lt;/a&gt;, Kubernetes&amp;rsquo; 
reporting tool. Spartakus does not report any personal information. 
See the &lt;a href=&#34;https://github.com/kubernetes-incubator/spartakus&#34;&gt;Spartakus docs&lt;/a&gt; for 
more detail.&lt;/p&gt;
&lt;p&gt;Allowing usage reporting is entirely voluntary.&lt;/p&gt;


&lt;div class=&#34;alert alert-info&#34; role=&#34;alert&#34;&gt;
&lt;h4 class=&#34;alert-heading&#34;&gt;Reporting usage data is one of the most significant contributions you can make to Kubeflow&lt;/h4&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;/div&gt;

&lt;h2 id=&#34;disable-usage-reporting-on-an-existing-kubeflow-deployment&#34;&gt;Disable usage reporting on an existing Kubeflow deployment&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;ve already deployed Kubeflow, run the following command to disable usage 
reporting on your existing deployment. The command removes the 
&lt;code&gt;spartakus-volunteer&lt;/code&gt; application:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;color:#204a87&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color:#000&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#ce5c00;font-weight:bold&#34;&gt;=&lt;/span&gt;kubeflow
kubectl delete -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; deploy spartakus-volunteer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;You can run the following command to check for existence of the application:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get -n &lt;span style=&#34;color:#4e9a06&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color:#000&#34;&gt;NAMESPACE&lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;}&lt;/span&gt; deploy spartakus-volunteer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;remove-usage-reporting-before-deploying-kubeflow&#34;&gt;Remove usage reporting before deploying Kubeflow&lt;/h2&gt;
&lt;p&gt;The following instructions assume that you plan to use the kfctl command-line
interface to deploy Kubeflow.&lt;/p&gt;
&lt;p&gt;This guide refers to the &lt;code&gt;${CONFIG_FILE}&lt;/code&gt;, which is the Kubeflow configuration 
file in your Kubeflow deployment directory. For example,
&lt;code&gt;${KF_DIR}/kfctl_k8s_istio.v1.0.0.yaml&lt;/code&gt; or 
&lt;code&gt;${KF_DIR}/kfctl_gcp_iap.v1.0.0.yaml&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To prevent Spartakus from being deployed:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Follow your chosen guide to deploying Kubeflow, but stop before you deploy
Kubeflow. For example, see the guide to 
&lt;a href=&#34;http://osmatrix.github.io/docs/started/k8s/kfctl-k8s-istio/&#34;&gt;deploying Kubeflow with kfctl_k8s_istio&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When you reach the 
&lt;a href=&#34;http://osmatrix.github.io/docs/started/k8s/kfctl-k8s-istio/#alt-set-up-and-deploy&#34;&gt;setup and deploy step&lt;/a&gt;,
&lt;strong&gt;skip the &lt;code&gt;kfctl apply&lt;/code&gt; command&lt;/strong&gt; and run the &lt;strong&gt;&lt;code&gt;kfctl build&lt;/code&gt;&lt;/strong&gt; command 
instead, as  described in the above guide. Now you can edit the configuration
files before deploying Kubeflow.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit your &lt;code&gt;${CONFIG_FILE}&lt;/code&gt; file as described &lt;a href=&#34;#remove-spartakus&#34;&gt;below&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Run the &lt;code&gt;kfctl apply&lt;/code&gt; command to deploy Kubeflow:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;cd ${KF_DIR}
kfctl apply -V -f ${CONFIG_FILE}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h3 id=&#34;removing-spartakus-from-your-configuration&#34;&gt;Removing Spartakus from your configuration&lt;/h3&gt;
&lt;p&gt;You need to remove the Spartakus entry from &lt;code&gt;KfDef.Spec.Applications&lt;/code&gt; in
the &lt;code&gt;${CONFIG_FILE}&lt;/code&gt; file. Find the &lt;code&gt;applications&lt;/code&gt; section of the YAML 
file and delete the following lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- kustomizeConfig:
    parameters:
    - initRequired: true
      name: usageId
      value: &amp;lt;randomly-generated-id&amp;gt;
    - initRequired: true
      name: reportUsage
      value: &amp;quot;true&amp;quot;
    repoRef:
      name: manifests
      path: common/spartakus
  name: spartakus
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Alternatively,&lt;/strong&gt; some YAML configuration files may include entries for 
&lt;code&gt;KfDef.Spec.Components&lt;/code&gt; and &lt;code&gt;KfDef.Spec.ComponentParams&lt;/code&gt; instead of 
&lt;code&gt;KfDef.Spec.Applications&lt;/code&gt;. In this case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Find the &lt;code&gt;componentParams&lt;/code&gt; section of the YAML file and delete the following 
lines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  spartakus:
  - initRequired: true
    name: usageId
    value: &amp;quot;&amp;lt;randomly-generated-id&amp;gt;&amp;quot;
  - initRequired: true
    name: reportUsage
    value: &amp;quot;true&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the &lt;code&gt;components&lt;/code&gt; section of the YAML file and delete the following 
line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  - spartakus
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Istio Usage in Kubeflow</title>
      <link>http://osmatrix.github.io/docs/other-guides/istio-in-kubeflow/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/istio-in-kubeflow/</guid>
      <description>
        
        
        &lt;p&gt;Kubeflow v0.6 onwards deploys Istio along with configuration to enable
end-to-end authentication and access control. This setup is the foundation
of multi-tenancy support in Kubeflow. A Kubeflow deployment without Istio is
not possible.&lt;/p&gt;
&lt;h2 id=&#34;a-gentle-introduction-to-istio&#34;&gt;A gentle introduction to Istio&lt;/h2&gt;
&lt;p&gt;Most modern applications are built using a distributed microservices
architecture. This ensures that each individual service is simple and has a
well defined responsibility. Complex systems and platforms are generally
built by combining many such microservices. Each microservice defines its own
APIs and the services interact with each other using these APIs in order to
serve end-user requests.&lt;/p&gt;
&lt;p&gt;The term &lt;em&gt;service mesh&lt;/em&gt; is used to describe the network of microservices that
make up such applications and the interactions between them. As a service mesh
grows in size and complexity, it can become harder to understand and manage.
Its requirements can include discovery, load balancing, failure recovery,
metrics, and monitoring. A service mesh also often has more complex operational
requirements, like A/B testing, canary rollouts, rate limiting, access control,
and end-to-end authentication.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt; is a pioneering and highly performant open source
implementation of service mesh by Google. For further details, you can read the
&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/&#34;&gt;conceptual overview&lt;/a&gt; of Istio.&lt;/p&gt;
&lt;h2 id=&#34;why-kubeflow-needs-istio&#34;&gt;Why Kubeflow needs Istio&lt;/h2&gt;
&lt;p&gt;Kubeflow is a collection of tools, frameworks and services that are deployed
together into a single Kubernetes cluster to enable end-to-end ML workflows.
Most of these components or services are developed independently and help with
different parts of the workflow. Developing a complete ML workflow or an ML
development environment requires combining multiple services and components.
Kubeflow provides the underlying infrastructure that makes it possible to put
such disparate components together.&lt;/p&gt;
&lt;p&gt;Kubeflow uses Istio as a uniform way to secure, connect, and monitor microservices. Specifically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Securing service-to-service communication in a Kubeflow deployment with
strong identity-based authentication and authorization.&lt;/li&gt;
&lt;li&gt;A policy layer for supporting access controls and quotas.&lt;/li&gt;
&lt;li&gt;Automatic metrics, logs, and traces for traffic within the deployment
including cluster ingress and egress.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;istio-in-kubeflow&#34;&gt;Istio in Kubeflow&lt;/h2&gt;
&lt;p&gt;The following diagram illustrates how user requests interact with services in
Kubeflow. It walks through the process when a user requests to create a new
notebook server via the Notebooks Servers UI accessible through the Kubeflow Central Dashboard.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The user request is intercepted by an identification proxy which talks to
a SSO service provider such as IAM on Cloud Services Provider or Active
Directory/LDAP on-premises.&lt;/li&gt;
&lt;li&gt;When the user is authenticated, the request is modified by the Istio
Gateway to include a JWT Header token containing the identity of the user.
All requests throughout the service mesh carry this token along.&lt;/li&gt;
&lt;li&gt;The Istio RBAC policies are applied on the incoming request to validate
the access to the service and the requested namespace. If either of those
are inaccessible to the user, an error response is sent back.&lt;/li&gt;
&lt;li&gt;If the request is validated, it is forwarded to the appropriate controller
(Notebooks Controller in this case).&lt;/li&gt;
&lt;li&gt;Notebooks Controller validates authorization with Kubernetes RBAC and creates the
notebook pod in the namespace that the user requested.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Further actions by the user with the notebook to create training jobs or other
resources in the namespace go through a similar process. Profiles Controller
manages the creation of profiles, and creates and applies appropriate Istio
policies. For more details, please see &lt;a href=&#34;http://osmatrix.github.io/docs/components/multi-tenancy/&#34;&gt;multi-user
isolation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;deploying-kubeflow-without-istio&#34;&gt;Deploying Kubeflow without Istio&lt;/h2&gt;
&lt;p&gt;Currently it is not possible to deploy Kubeflow without Istio. Kubeflow needs the Istio
Custom Resource Definitions (CRDs) to express the new route to access the
created Notebook from the Gateway.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Job Scheduling</title>
      <link>http://osmatrix.github.io/docs/other-guides/job-scheduling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/job-scheduling/</guid>
      <description>
        
        
        &lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;  &amp;lt;a href=&amp;quot;https://github.com/kubeflow/tf-operator/issues&amp;quot;&amp;gt;feedback&amp;lt;/a&amp;gt;&amp;lt;/h4&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;about the usability of the feature.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;This guide describes how to use &lt;a href=&#34;https://github.com/volcano-sh/volcano&#34;&gt;volcano scheduler&lt;/a&gt; to support gang-scheduling in 
Kubeflow, to allow jobs to run multiple pods at the same time.&lt;/p&gt;
&lt;h2 id=&#34;running-jobs-with-gang-scheduling&#34;&gt;Running jobs with gang-scheduling&lt;/h2&gt;
&lt;p&gt;To use gang-scheduling, you have to install volcano scheduler in your cluster first as a secondary scheduler of Kubernetes and configure operator to enable gang-scheduling.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Follow the &lt;a href=&#34;https://github.com/volcano-sh/volcano&#34;&gt;instructions in the volcano repository&lt;/a&gt; to install Volcano.&lt;/li&gt;
&lt;li&gt;Take tf-operator for example, enable gang-scheduling in tf-operator by setting true to &lt;code&gt;--enable-gang-scheduling&lt;/code&gt; flag.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Volcano scheduler and operator in Kubeflow achieve gang-scheduling by using &lt;a href=&#34;https://github.com/volcano-sh/volcano/blob/master/pkg/apis/scheduling/types.go&#34;&gt;PodGroup&lt;/a&gt;. operator will create the PodGroup of the job automatically.&lt;/p&gt;
&lt;p&gt;The yaml to use volcano scheduler to schedule your job as a gang is the same as non-gang-scheduler, for example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;apiVersion&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;kubeflow.org/v1beta1&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;kind&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;TFJob&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;metadata&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#34;tfjob-gang-scheduling&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;&lt;/span&gt;spec&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;  &lt;/span&gt;tfReplicaSpecs&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;Worker&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;replicas&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;template&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;spec&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;containers&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;- args&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- python&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- tf_cnn_benchmarks.py&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --batch_size=&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;32&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --model=resnet50&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --variable_update=parameter_server&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --flush_stdout=&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --num_gpus=&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --local_parameter_device=cpu&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --device=gpu&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --data_format=NHWC&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;gcr.io/kubeflow/tf-benchmarks-gpu&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;v20171202-bdab599-dirty-284af3&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;tensorflow&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;resources&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;              &lt;/span&gt;limits&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;                &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;nvidia.com/gpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workingDir&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;/opt/tf-benchmarks/scripts/tf_cnn_benchmarks&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;restartPolicy&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;OnFailure&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;    &lt;/span&gt;PS&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;replicas&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;      &lt;/span&gt;template&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;        &lt;/span&gt;spec&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;containers&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;- args&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- python&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- tf_cnn_benchmarks.py&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --batch_size=&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;32&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --model=resnet50&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --variable_update=parameter_server&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --flush_stdout=&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --num_gpus=&lt;span style=&#34;color:#0000cf;font-weight:bold&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --local_parameter_device=cpu&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --device=cpu&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;- --data_format=NHWC&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;image&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;gcr.io/kubeflow/tf-benchmarks-cpu&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;v20171202-bdab599-dirty-284af3&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;name&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;tensorflow&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;resources&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;              &lt;/span&gt;limits&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;                &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;cpu&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#4e9a06&#34;&gt;&amp;#39;1&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;            &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;workingDir&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;/opt/tf-benchmarks/scripts/tf_cnn_benchmarks&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;          &lt;/span&gt;&lt;span style=&#34;color:#204a87;font-weight:bold&#34;&gt;restartPolicy&lt;/span&gt;&lt;span style=&#34;color:#000;font-weight:bold&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt; &lt;/span&gt;OnFailure&lt;span style=&#34;color:#f8f8f8;text-decoration:underline&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;about-volcano-scheduler-and-gang-scheduling&#34;&gt;About volcano scheduler and gang-scheduling&lt;/h2&gt;
&lt;p&gt;With using volcano scheduler to apply gang-scheduling, a job can run only if there are enough resources for all the pods of the job. Otherwise, all the pods will be in pending state waiting for enough resources. For example, if a job requiring N pods is created and there are only enough resources to schedule N-2 pods, then N pods of the job will stay pending.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; when in a high workload, if a pod of the job dies when the job is still running, it might give other pods chance to occupied the resources and cause deadlock.&lt;/p&gt;
&lt;h2 id=&#34;troubleshooting&#34;&gt;Troubleshooting&lt;/h2&gt;
&lt;p&gt;If you keep getting problems related to RBAC in your volcano scheduler.&lt;/p&gt;
&lt;p&gt;You can try to add the following rules into your clusterrole of scheduler used by volcano scheduler.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- apiGroups:
  - &#39;*&#39;
  resources:
  - &#39;*&#39;
  verbs:
  - &#39;*&#39;
&lt;/code&gt;&lt;/pre&gt;
      </description>
    </item>
    
    <item>
      <title>Docs: Troubleshooting</title>
      <link>http://osmatrix.github.io/docs/other-guides/troubleshooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/troubleshooting/</guid>
      <description>
        
        
        &lt;p&gt;This page presents some hints for troubleshooting specific problems that you
may encounter.&lt;/p&gt;
&lt;h2 id=&#34;macos-kfctl-cannot-be-opened-because-the-developer-cannot-be-verified&#34;&gt;macOS: kfctl cannot be opened because the developer cannot be verified&lt;/h2&gt;
&lt;p&gt;The kfctl binary is currently not signed. That is, kfctl is not registered
with Apple. When you run kfctl from the command
line on the latest versions of macOS, you may see a message like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;kfctl&amp;rdquo; cannot be opened because the developer cannot be verified.&lt;/strong&gt; macOS
cannot verify that this app is free from malware.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To run kfctl, go to the kfctl binary file in &lt;em&gt;Finder&lt;/em&gt;, right-click, then select
&lt;strong&gt;Open&lt;/strong&gt;. Then click &lt;strong&gt;Open&lt;/strong&gt; again to confirm that you want to open the app.&lt;/p&gt;
&lt;p&gt;For more information, see the &lt;a href=&#34;https://support.apple.com/en-au/guide/mac-help/mh40616/10.15/mac/10.15&#34;&gt;macOS user 
guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;tensorflow-and-avx&#34;&gt;TensorFlow and AVX&lt;/h2&gt;
&lt;p&gt;There are some instances where you may encounter a TensorFlow-related Python installation or a pod launch issue that results in a SIGILL (illegal instruction core dump). Kubeflow uses the pre-built binaries from the TensorFlow project which, beginning with version 1.6, are compiled to make use of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Advanced_Vector_Extensions&#34;&gt;AVX&lt;/a&gt; CPU instruction. This is a recent feature and your CPU might not support it. Check the host environment for your node to determine whether it has this support.&lt;/p&gt;
&lt;p&gt;Linux:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grep -ci avx /proc/cpuinfo
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;avx2&#34;&gt;AVX2&lt;/h3&gt;
&lt;p&gt;Some components requirement AVX2 for better performance, e.g. TF Serving.
To ensure the nodes support AVX2, we added
&lt;a href=&#34;https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform&#34;&gt;minCpuPlatform&lt;/a&gt;
arg in our deployment
&lt;a href=&#34;https://github.com/kubeflow/manifests/blob/master/gcp/deployment_manager_configs/cluster.jinja#L131&#34;&gt;config&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On GCP this will fail in regions (e.g. us-central1-a) that do not explicitly have Intel
Haswell (even when there are other newer platforms in the region).
In that case, please choose another region, or change the config to other
&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures&#34;&gt;platform&lt;/a&gt;
newer than Haswell.&lt;/p&gt;
&lt;h2 id=&#34;rbac-clusters&#34;&gt;RBAC clusters&lt;/h2&gt;
&lt;p&gt;If you are running on a Kubernetes cluster with &lt;a href=&#34;https://kubernetes.io/docs/admin/authorization/rbac/#command-line-utilities&#34;&gt;RBAC enabled&lt;/a&gt;, you may get an error like the following when deploying Kubeflow:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR Error updating roles kubeflow-test-infra.jupyter-role: roles.rbac.authorization.k8s.io &amp;quot;jupyter-role&amp;quot; is forbidden: attempt to grant extra privileges: [PolicyRule{Resources:[&amp;quot;*&amp;quot;], APIGroups:[&amp;quot;*&amp;quot;], Verbs:[&amp;quot;*&amp;quot;]}] user=&amp;amp;{your-user@acme.com  [system:authenticated] map[]} ownerrules=[PolicyRule{Resources:[&amp;quot;selfsubjectaccessreviews&amp;quot;], APIGroups:[&amp;quot;authorization.k8s.io&amp;quot;], Verbs:[&amp;quot;create&amp;quot;]} PolicyRule{NonResourceURLs:[&amp;quot;/api&amp;quot; &amp;quot;/api/*&amp;quot; &amp;quot;/apis&amp;quot; &amp;quot;/apis/*&amp;quot; &amp;quot;/healthz&amp;quot; &amp;quot;/swagger-2.0.0.pb-v1&amp;quot; &amp;quot;/swagger.json&amp;quot; &amp;quot;/swaggerapi&amp;quot; &amp;quot;/swaggerapi/*&amp;quot; &amp;quot;/version&amp;quot;], Verbs:[&amp;quot;get&amp;quot;]}] ruleResolutionErrors=[]
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This error indicates you do not have sufficient permissions. In many cases you can resolve this just by creating an appropriate
clusterrole binding like so and then redeploying kubeflow:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-commandline&#34; data-lang=&#34;commandline&#34;&gt;kubectl create clusterrolebinding default-admin --clusterrole=cluster-admin --user=your-user@acme.com
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Replace &lt;code&gt;your-user@acme.com&lt;/code&gt; with the user listed in the error message.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you&amp;rsquo;re using GKE, you may want to refer to &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control&#34;&gt;GKE&amp;rsquo;s RBAC docs&lt;/a&gt; to understand
how RBAC interacts with IAM on GCP.&lt;/p&gt;
&lt;h2 id=&#34;problems-spawning-jupyter-pods&#34;&gt;Problems spawning Jupyter pods&lt;/h2&gt;
&lt;p&gt;This section has been moved to [Jupyter Notebooks Troubleshooting Guide] (/docs/notebooks/troubleshoot/).&lt;/p&gt;
&lt;h2 id=&#34;pods-stuck-in-pending-state&#34;&gt;Pods stuck in Pending state&lt;/h2&gt;
&lt;p&gt;There are three pods that have Persistent Volume Claims (PVCs) that will get stuck in pending state if they are unable to bind their PVC. The three pods are minio, mysql, and katib-mysql.
Check the status of the PVC requests:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;kubectl -n ${NAMESPACE} get pvc
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;Look for the status of &amp;ldquo;Bound&amp;rdquo;&lt;/li&gt;
&lt;li&gt;PVC requests in &amp;ldquo;Pending&amp;rdquo; state indicate that the scheduler was unable to bind the required PVC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you have not configured [dynamic provisioning] (&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&#34;&gt;https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/&lt;/a&gt;) for your cluster, including a default storage class, then you must create a [persistent volume] (&lt;a href=&#34;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&#34;&gt;https://kubernetes.io/docs/concepts/storage/persistent-volumes/&lt;/a&gt;) for each of the PVCs.&lt;/p&gt;
&lt;p&gt;You can use the example below to create local persistent volumes:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-commandline&#34; data-lang=&#34;commandline&#34;&gt;sudo mkdir /mnt/pv{1..3}

kubectl create -f - &amp;lt;&amp;lt;EOF
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pv-volume1
spec:
  storageClassName:
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &amp;quot;/mnt/pv1&amp;quot;
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pv-volume2
spec:
  storageClassName:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &amp;quot;/mnt/pv2&amp;quot;
---
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pv-volume3
spec:
  storageClassName:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &amp;quot;/mnt/pv3&amp;quot;
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once created the scheduler will successfully start the remaining three pods. The PVs may also be created prior to running any of the kfctl commands.&lt;/p&gt;
&lt;h2 id=&#34;openshift&#34;&gt;OpenShift&lt;/h2&gt;
&lt;p&gt;If you are deploying Kubeflow in an &lt;a href=&#34;https://github.com/openshift/origin&#34;&gt;OpenShift&lt;/a&gt; environment which encapsulates Kubernetes, you will need to adjust the security contexts for the ambassador and Jupyter-hub deployments in order to get the pods to run:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-commandline&#34; data-lang=&#34;commandline&#34;&gt;oc adm policy add-scc-to-user anyuid -z ambassador
oc adm policy add-scc-to-user anyuid -z jupyter-hub
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the anyuid policy has been set, you must delete the failing pods and allow them to be recreated in the project deployment.&lt;/p&gt;
&lt;p&gt;You will also need to adjust the privileges of the tf-job-operator service account for TFJobs to run. Do this in the project where you are running TFJobs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-commandline&#34; data-lang=&#34;commandline&#34;&gt;oc adm policy add-role-to-user cluster-admin -z tf-job-operator
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;403-api-rate-limit-exceeded-error&#34;&gt;403 API rate limit exceeded error&lt;/h2&gt;
&lt;p&gt;Because kubectl uses GitHub to pull kubeflow, unless user specifies GitHub API token, it will quickly consume maximum API call quota for anonymous.
To fix this issue first create GitHub API token using this &lt;a href=&#34;https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/&#34;&gt;guide&lt;/a&gt;, and assign this token to GITHUB_TOKEN environment variable:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-commandline&#34; data-lang=&#34;commandline&#34;&gt;export GITHUB_TOKEN=&amp;lt;&amp;lt; token &amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;next-steps&#34;&gt;Next steps&lt;/h2&gt;
&lt;p&gt;Visit the &lt;a href=&#34;http://osmatrix.github.io/docs/other-guides/support/&#34;&gt;Kubeflow support page&lt;/a&gt; to find resources
and community forums where you can ask for help.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Frequently Asked Questions</title>
      <link>http://osmatrix.github.io/docs/other-guides/freq-ask-questions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/freq-ask-questions/</guid>
      <description>
        
        
        &lt;h3 id=&#34;is-deploying-kubeflow-with-helm-supported&#34;&gt;Is deploying Kubeflow with Helm supported?&lt;/h3&gt;
&lt;p&gt;No, Kubeflow only provides Kustomize packages for Kubeflow applications. So deploying Kubeflow isn&amp;rsquo;t supported except via Kustomize.&lt;/p&gt;
&lt;p&gt;Kubeflow makes use of &lt;a href=&#34;https://kustomize.io/&#34;&gt;Kustomize&lt;/a&gt; to help customize Kubeflow for different platforms and configurations.&lt;/p&gt;
&lt;p&gt;However, once you deploy Kubeflow you can express Kubernetes resources using YAML, Kustomize, Helm or whatever tool you like.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Support</title>
      <link>http://osmatrix.github.io/docs/other-guides/support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://osmatrix.github.io/docs/other-guides/support/</guid>
      <description>
        
        
        &lt;p&gt;This page describes the Kubeflow resources and support options that you can
explore when you encounter a problem, have a question, or want to make a
suggestion about Kubeflow.&lt;/p&gt;
&lt;h2 id=&#34;levels-of-support&#34;&gt;Levels of support&lt;/h2&gt;
&lt;p&gt;Kubeflow applications offer various levels of support, based on the application
status. To see the status of each application, refer to the 
&lt;a href=&#34;http://osmatrix.github.io/docs/reference/version-policy/#kubeflow-application-matrix&#34;&gt;Kubeflow application 
matrix&lt;/a&gt; on the
version policies page.&lt;/p&gt;
&lt;p&gt;The following table describes the level of support that you can expect based on
the status of an application:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Kubeflow has an active and helpful community of users and contributors.&lt;/p&gt;
&lt;p&gt;The Kubeflow community offers support on a best-effort basis for stable and beta
applications.
&lt;strong&gt;Best-effort support&lt;/strong&gt; means that there&amp;rsquo;s no formal agreement or
commitment to solve a problem but the community appreciates the
importance of addressing the problem as soon as possible. The community commits
to helping you diagnose and address the problem if all the following are true:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The cause falls within the technical framework that Kubeflow controls. For
example, the Kubeflow community may not be able to help if the problem is 
caused by a specific network configuration within your organization.&lt;/li&gt;
&lt;li&gt;Community members can reproduce the problem.&lt;/li&gt;
&lt;li&gt;The reporter of the problem can help with further diagnosis and 
troubleshooting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can ask questions and make suggestions in the following places:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Slack&lt;/strong&gt; for online chat and messaging. See details of Kubeflow&amp;rsquo;s 
&lt;a href=&#34;http://osmatrix.github.io/docs/about/community/#slack&#34;&gt;Slack workspace and channels&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kubeflow discuss&lt;/strong&gt; for email-based group discussion. Join the
&lt;a href=&#34;https://groups.google.com/forum/#!forum/kubeflow-discuss&#34;&gt;kubeflow-discuss&lt;/a&gt; 
group.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kubeflow documentation&lt;/strong&gt; for overviews and how-to guides. In particular,
refer to the following documents when troubleshooting a problem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://osmatrix.github.io/docs/started/getting-started/&#34;&gt;Kubeflow installation and setup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://osmatrix.github.io/docs/components/&#34;&gt;Kubeflow components&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://osmatrix.github.io/docs/other-guides/&#34;&gt;Further setup and troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kubeflow issue trackers&lt;/strong&gt; for known issues, questions, and feature requests.
Search the open issues to see if someone else has already logged the problem 
that you&amp;rsquo;re encountering and learn about any workarounds to date. If no one
has logged your problem, create a new issue to describe the problem.&lt;/p&gt;
&lt;p&gt;Each Kubeflow application has its own issue tracker within the &lt;a href=&#34;https://github.com/kubeflow&#34;&gt;Kubeflow
organization on GitHub&lt;/a&gt;. To get you started,
here are the primary issue trackers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/kubeflow/issues&#34;&gt;Kubeflow core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/kfctl/issues&#34;&gt;kfctl command-line tool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/manifests/issues&#34;&gt;Kustomize manifests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/pipelines/issues&#34;&gt;Kubeflow Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/katib/issues&#34;&gt;Katib hyperparameter tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/metadata/issues&#34;&gt;Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/fairing/issues&#34;&gt;Fairing notebook SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/tf-operator/issues&#34;&gt;TensorFlow training (TFJob)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/pytorch-operator/issues&#34;&gt;PyTorch training (PyTorchJob)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/kfserving/issues&#34;&gt;KFServing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/examples/issues&#34;&gt;Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/website/issues&#34;&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;support-from-providers-in-the-kubeflow-ecosystem&#34;&gt;Support from providers in the Kubeflow ecosystem&lt;/h2&gt;
&lt;p&gt;The following organizations offer advice and support for Kubeflow deployments:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;h2 id=&#34;support-from-a-cloud-or-platform-provider&#34;&gt;Support from a cloud or platform provider&lt;/h2&gt;
&lt;p&gt;If you&amp;rsquo;re using the services of a cloud provider to host Kubeflow, the cloud
provider may be able to help you diagnose and solve a problem.&lt;/p&gt;
&lt;p&gt;Consult the support page for the cloud service or platform that you&amp;rsquo;re using:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/contact-us/&#34;&gt;Amazon Web Services (AWS)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/support-hub/&#34;&gt;Google Cloud Platform (GCP)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ibm.com/cloud/support&#34;&gt;IBM Cloud Private&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://azure.microsoft.com/en-au/support/options/&#34;&gt;Microsoft Azure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://help.openshift.com/&#34;&gt;Red Hat OpenShift&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other-places-to-ask-questions&#34;&gt;Other places to ask questions&lt;/h2&gt;
&lt;p&gt;You can also try searching for answers or asking a question on Stack Overflow. 
See the &lt;a href=&#34;https://stackoverflow.com/questions/tagged/kubeflow&#34;&gt;questions tagged with
“kubeflow”&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;getting-involved-in-the-kubeflow-community&#34;&gt;Getting involved in the Kubeflow community&lt;/h2&gt;
&lt;p&gt;You can get involved with Kubeflow in many ways. For example, you can
contribute to the Kubeflow code or documentation. You can join the community
meetings to talk to maintainers about a specific topic. See the
&lt;a href=&#34;http://osmatrix.github.io/docs/about/community/&#34;&gt;Kubeflow community page&lt;/a&gt; for further information.&lt;/p&gt;
&lt;h2 id=&#34;following-the-news&#34;&gt;Following the news&lt;/h2&gt;
&lt;p&gt;Keep up with Kubeflow news:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The &lt;a href=&#34;https://medium.com/kubeflow&#34;&gt;Kubeflow blog&lt;/a&gt; is the primary channel for
announcement of new releases, events, and technical walkthroughs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Follow &lt;a href=&#34;https://twitter.com/kubeflow&#34;&gt;Kubeflow on Twitter&lt;/a&gt; for shared
technical tips.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The release notes give details of the latest updates for each Kubeflow 
application.&lt;/p&gt;
&lt;p&gt;Each Kubeflow application has its own repository within the &lt;a href=&#34;https://github.com/kubeflow&#34;&gt;Kubeflow
organization on GitHub&lt;/a&gt;. Some of the 
applications publish release notes. To get you started,
here are the release notes for the primary applications:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/kubeflow/releases&#34;&gt;Kubeflow core&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/pipelines/releases&#34;&gt;Kubeflow Pipelines&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/katib/releases&#34;&gt;Katib hyperparameter tuning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/metadata/releases&#34;&gt;Metadata&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/fairing/releases&#34;&gt;Fairing notebook SDK&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/tf-operator/releases&#34;&gt;TensorFlow training (TFJob)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/pytorch-operator/releases&#34;&gt;PyTorch training (PyTorchJob)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubeflow/kfserving/releases&#34;&gt;KFServing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
